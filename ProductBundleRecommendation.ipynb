{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Bundle Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Order_Products_Prior_DF = pd.read_csv('../data/order_products_prior.csv')\n",
    "ordersDF = pd.read_csv('../data/orders.csv')\n",
    "productsDF = pd.read_csv('../data/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Organic Egg Whites'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orders in prior merged with product names\n",
    "Order_Product_Name_Prior = pd.merge(Order_Products_Prior_DF, \n",
    "                                    productsDF, how='left', on='product_id')\n",
    "# Prior orders with user_id, product_id, product_name\n",
    "Prior_User_Order_Product = pd.merge(Order_Product_Name_Prior, \n",
    "                                    ordersDF, how='left', on='order_id')\n",
    "\n",
    "Prior_User_Order_Product['product_name'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the product name is a string seperated with whitespace. We want to replace all whitespace with underscore \"_\", so that each product name is actually one word with no space in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = Prior_User_Order_Product['product_name']\n",
    "product_no_space = []\n",
    "for product in products:\n",
    "    product = product.replace(\" \", \"_\")\n",
    "    product_no_space.append(product)\n",
    "\n",
    "# drop original column, replace it with one with no space\n",
    "Prior_User_Order_Product.drop(['product_name'], axis=1)\n",
    "Prior_User_Order_Product['product_name'] = product_no_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to have a dataframe with each row correspons to one order. The first column is each order_id. The second column is the names of all products correspond to each order_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add product name to each user\n",
    "name_list = []\n",
    "for p_name in Prior_User_Order_Product.groupby('order_id')['product_name']:\n",
    "    name_list.append(' '.join(p_name[1]))\n",
    "    \n",
    "order_id = Prior_User_Order_Product.groupby('order_id')['product_name'].agg('count').index\n",
    "order_products = pd.DataFrame({'order_id':order_id, 'products':name_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a glimpse of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Organic_Egg_Whites Michigan_Organic_Kale Garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Total_2%_with_Strawberry_Lowfat_Greek_Strained...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Plain_Pre-Sliced_Bagels Honey/Lemon_Cough_Drop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Bag_of_Organic_Bananas Just_Crisp,_Parmesan Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Cleanse Dryer_Sheets_Geranium_Scent Clean_Day_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id                                           products\n",
       "0         2  Organic_Egg_Whites Michigan_Organic_Kale Garli...\n",
       "1         3  Total_2%_with_Strawberry_Lowfat_Greek_Strained...\n",
       "2         4  Plain_Pre-Sliced_Bagels Honey/Lemon_Cough_Drop...\n",
       "3         5  Bag_of_Organic_Bananas Just_Crisp,_Parmesan Fr...\n",
       "4         6  Cleanse Dryer_Sheets_Geranium_Scent Clean_Day_..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are going to use PySpark to extract bigrams, we need to prepare the dataframe in a format required by PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFrameList = []\n",
    "index = 0\n",
    "for row in order_products['products']:\n",
    "    productsName = row.split(' ')\n",
    "    tup = (index, productsName)\n",
    "    dataFrameList.append(tup)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly split data into train (70%) and test (30%)\n",
    "import random\n",
    "import numpy\n",
    "random.shuffle(dataFrameList)\n",
    "\n",
    "train_data = dataFrameList[:2250411]\n",
    "test_data = dataFrameList[2250411:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PySpark to Extract Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First convert the data to spark dataframe. To reduce computation, we will read 10000 lines each time, and then combine all into one spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Bigram\").getOrCreate()\n",
    "\n",
    "# spark dataframeï¼š read in batch of 10000 due to large computation\n",
    "N = len(train_data)//10000\n",
    "mod = len(train_data) % 10000\n",
    "trainDF = spark.createDataFrame(dataFrameList[0:10000], ['id',\"product_name\"])\n",
    "\n",
    "for i in range(1,N):\n",
    "    trainDF_sub = spark.createDataFrame(train_data[10000*i:10000*(i+1)], ['id',\"product_name\"])\n",
    "    traintDF = trainDF.union(trainDF_sub)\n",
    "    \n",
    "trainDF_sub = spark.createDataFrame(train_data[10000*N:len(train_data)], ['id',\"product_name\"])\n",
    "trainDF = trainDF.union(trainDF_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=3072566, product_name=['Twelve_Essentials_Fruit_and_Vegetable_Juice', 'Juice,_Vegetable_&_Fruit,_Fuel', 'Juice,_Vegetable_&_Fruit,_Purify'], bigrams=['Twelve_Essentials_Fruit_and_Vegetable_Juice Juice,_Vegetable_&_Fruit,_Fuel', 'Juice,_Vegetable_&_Fruit,_Fuel Juice,_Vegetable_&_Fruit,_Purify'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get bigram\n",
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "ngram = NGram(n=2, inputCol=\"product_name\", outputCol=\"bigrams\")\n",
    "ngramDataFrame = ngram.transform(trainDF)\n",
    "\n",
    "ngramDataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after we got the bigrams, we start counting the frequency of each.\n",
    "\n",
    "Bigrams are stored in a nested dictionary:\n",
    "+ first layer key is the first word in a bigram \n",
    "+ second layer key is the second word in a bigram\n",
    "+ the second layer value is the frequency. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count frequency:\n",
    "# Bigrams are stored in a nested dictionary:\n",
    "# first layer key is the first word in a bigram \n",
    "# second layer key is the second word in a bigram\n",
    "# the second layer value is the frequency. \n",
    "# {'Organic_Mint_Bunch': {'Organic_Navel_Orange':2, 'c':2}}\n",
    "\n",
    "bigrams = ngramDataFrame.toPandas()['bigrams']\n",
    "table = {}\n",
    "total = len(bigrams)\n",
    "completion = 0\n",
    "for bigram in bigrams:\n",
    "    for combination in bigram:\n",
    "        components = combination.split(' ')\n",
    "        key = components[0]\n",
    "        valKey = components[1]\n",
    "        if key in table:\n",
    "            valueDict = table[key]\n",
    "            if valKey in valueDict:\n",
    "                valueDict[valKey] = valueDict[valKey] + 1\n",
    "            else:\n",
    "                valueDict[valKey] = 1\n",
    "        else:\n",
    "            # create new value for key\n",
    "            valueDict =  {valKey: 1}\n",
    "            table[key] = valueDict\n",
    "    completion += 1\n",
    "#     print(\"==>\", float(completion / total) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which combination appears more than 20 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organic_Hass_Avocado  +  Bag_of_Organic_Bananas :  26\n",
      "Banana  +  Organic_Avocado :  36\n",
      "Banana  +  Organic_Fuji_Apple :  25\n",
      "Banana  +  Honeycrisp_Apple :  23\n",
      "Banana  +  Organic_Strawberries :  27\n",
      "Bag_of_Organic_Bananas  +  Organic_Strawberries :  31\n",
      "Bag_of_Organic_Bananas  +  Organic_Hass_Avocado :  30\n",
      "Bag_of_Organic_Bananas  +  Organic_Baby_Spinach :  23\n",
      "Organic_Avocado  +  Banana :  22\n",
      "Large_Lemon  +  Limes :  24\n"
     ]
    }
   ],
   "source": [
    "for firstWord in table:\n",
    "    for secondWord in table[firstWord]:\n",
    "        if table[firstWord][secondWord] > 20:\n",
    "            print(firstWord, \" + \", secondWord, \": \", table[firstWord][secondWord])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will use the frequencies above to generate recommendations for each product. We define functions to realize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPureData(prodName):\n",
    "    \n",
    "    '''sort the bigram frequencies in descending order, \n",
    "       then return merely the corresponding product names in the same order'''\n",
    "    \n",
    "    if prodName not in table:\n",
    "        return []\n",
    "    sortedOringalList = sorted(table[prodName].items(), key=lambda x: x[1], reverse=True)\n",
    "#     print(sortedOringalList)\n",
    "    data = {}\n",
    "    for tp in sortedOringalList:\n",
    "        product = tp[0]\n",
    "        number = tp[1]\n",
    "        if number in data:\n",
    "            productList = data[number]\n",
    "            productList.append(product)\n",
    "        else:\n",
    "            productList = [product]\n",
    "        data[number] = productList\n",
    "#     print(data)\n",
    "#     print(\"==> Get pure data name:\")\n",
    "    pureData = data.values()\n",
    "#     print(pureData)\n",
    "    return list(pureData)\n",
    "\n",
    "def pickRecommendProds(pureData, numberOfRecommend):\n",
    "    \n",
    "    '''Pick certain number of products from the sorted product names'''\n",
    "    \n",
    "    recommendProds = []\n",
    "    for prods in pureData:\n",
    "        if len(prods) <= numberOfRecommend:\n",
    "            recommendProds += prods\n",
    "            numberOfRecommend -= len(prods)\n",
    "        else:\n",
    "            recommendProds += random.sample(prods, numberOfRecommend)\n",
    "            numberOfRecommend = 0\n",
    "\n",
    "        if numberOfRecommend == 0:\n",
    "            break\n",
    "    \n",
    "    return recommendProds\n",
    "\n",
    "# recommend products bought together with 'name'\n",
    "# name: the product to start with\n",
    "def getRecommend(name, numberOfRecommend):\n",
    "    \n",
    "    '''Recommend certain number of products bought after the given input name'''\n",
    "    \n",
    "    # numberOfRecommend = 10\n",
    "    recommendProducts = []\n",
    "    productName = name\n",
    "    index = 0\n",
    "\n",
    "    while (numberOfRecommend):\n",
    "#         print(\"->Target: \", productName)\n",
    "#         print(\"->numberOfRecommend: \", numberOfRecommend)\n",
    "#         print(\"->Index: \", index)\n",
    "        data = getPureData(productName)\n",
    "    #     print(\"Pure data:\", data)\n",
    "        intermediate = pickRecommendProds(data, numberOfRecommend)\n",
    "        recommendProducts += intermediate\n",
    "#         print(\"Recommend: \", recommendProducts)\n",
    "#         print(\"Recommend: \", recommendProducts)\n",
    "        if len(intermediate) == 0 and index == len(recommendProducts):\n",
    "            break\n",
    "        numberOfRecommend -= len(intermediate)\n",
    "        if numberOfRecommend > 0:\n",
    "#             print(\"Still left: \", numberOfRecommend)\n",
    "            productName = recommendProducts[index]\n",
    "            index += 1\n",
    "\n",
    "#         print(\"==================\")\n",
    "\n",
    "    return recommendProducts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try an example: 15 Products recommended after \"Organic_Mint_Bunch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Organic_Italian_Parsley_Bunch', 'Garlic', 'Organic_Carrot_Bunch', 'Fresh_Cauliflower', 'Organic_Cilantro', 'Organic_Baby_Spinach_Salad', 'Organic_Cilantro_Bunch', 'Organic_Thyme', '100%_Pressed_Apple__Fruit_Juice', 'Organic_Mountain_Forest_Honey_Light_Amber', 'Organic_Cilantro', 'Large_Lemon', 'Organic_Mint', 'Organic_Basil', 'Organic_Garlic']\n"
     ]
    }
   ],
   "source": [
    "print(getRecommend(\"Organic_Mint_Bunch\", 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see how it performs on test data.\n",
    "\n",
    "We evaluate it by seeing in each order, how many products bought are in recommend list.\n",
    "\n",
    "For example, test_order_1 in test data contains 10 products.\n",
    "\n",
    "We start by recommend what can be bought with the first product, and we will give 10 recommendations (which is of same size as the actual order). We compare the next 9 actually bought products with this 10 recommendations. If there's a match, we will add 1 to the total score. Then we move to the second actually bought product, and give another 10 recommendations bought with the second product. Compare again, and compute total scores. ... After iterate through all actually bought products in this order, we have the total score, and divide the score by the order size to get the final_score_1 for test order 1.\n",
    "\n",
    "We save all final scores in one list and compute the average score in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestScore(test_data):\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    for order_info in test_data:\n",
    "        this_order = order_info[1]\n",
    "        order_len = len(this_order)\n",
    "        #print('order:', this_order)\n",
    "        #print('length of order', order_len)\n",
    "        i = 0\n",
    "        this_score = 0\n",
    "\n",
    "        while (i < order_len):\n",
    "            if this_order[i] in table:\n",
    "                # use original order length as the num of recommendation\n",
    "                recommends = getRecommend(this_order[i], order_len)\n",
    "                #print('====> recommends of ', this_order[i], \" : \", recommends)\n",
    "                laterProds = this_order[i:]\n",
    "                # check if the recommended products is included in order\n",
    "                for prod in laterProds:\n",
    "                    if prod in recommends:\n",
    "                        #print(\"-->\", prod)\n",
    "                        this_score += 1\n",
    "                i += 1\n",
    "            else:\n",
    "                # if the product is not trained in model, skip\n",
    "                i += 1\n",
    "                order_len -= 1\n",
    "\n",
    "        #print(this_score)\n",
    "        if not order_len == 0:\n",
    "            scores.append(this_score/order_len)\n",
    "        #print(scores)\n",
    "        \n",
    "    # return a list of predicted scores\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> Mean Test Scores:  0.182374730607\n"
     ]
    }
   ],
   "source": [
    "scores = TestScore(test_data)\n",
    "print(\"======> Mean Test Scores: \", numpy.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
